{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263d6302-6bba-47b7-b89f-e89e95cda228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import detrend\n",
    "\n",
    "# from windspharm.xarray import VectorWind\n",
    "import torch_harmonics as harmonics\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import credit.pol_lapdiff_filt as plf\n",
    "\n",
    "import xarray as xr \n",
    "import os \n",
    "import numpy as np \n",
    "import sys \n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "import pickle\n",
    "# from eofs.xarray import Eof\n",
    "\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from functools import lru_cache\n",
    "\n",
    "import math\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from random import random\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58999ff6-1339-43ba-aa28-966f13cb8489",
   "metadata": {},
   "source": [
    "## Open Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ffe1afc-c663-4225-b252-4ceada155e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = []\n",
    "for yryr in range(1979,2015):\n",
    "    DSdo_1 = xr.open_zarr(f'/glade/campaign/cisl/aiml/wchapman/MLWPS/STAGING/f.e21.CREDIT_climate_{yryr}_ERA5scaled_F32.zarr')\n",
    "    conc.append(DSdo_1)\n",
    "\n",
    "DSzarr1 = xr.concat(conc, dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee330d6a-80cb-42db-b558-ed57888bfab8",
   "metadata": {},
   "source": [
    "## Stream Function from ML Run using Torch Harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45f3d5b6-cbd9-4045-a272-dd06ea8213a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing timestep 100/10317\n",
      "Processing timestep 200/10317\n",
      "Processing timestep 300/10317\n",
      "Processing timestep 400/10317\n",
      "Processing timestep 500/10317\n",
      "Processing timestep 600/10317\n",
      "Processing timestep 700/10317\n",
      "Processing timestep 800/10317\n",
      "Processing timestep 900/10317\n",
      "Processing timestep 1000/10317\n",
      "Processing timestep 1100/10317\n",
      "Processing timestep 1200/10317\n",
      "Processing timestep 1300/10317\n",
      "Processing timestep 1400/10317\n",
      "Processing timestep 1500/10317\n",
      "Processing timestep 1600/10317\n",
      "Processing timestep 1700/10317\n",
      "Processing timestep 1800/10317\n",
      "Processing timestep 1900/10317\n",
      "Processing timestep 2000/10317\n",
      "Processing timestep 2100/10317\n",
      "Processing timestep 2200/10317\n",
      "Processing timestep 2300/10317\n",
      "Processing timestep 2400/10317\n",
      "Processing timestep 2500/10317\n",
      "Processing timestep 2600/10317\n",
      "Processing timestep 2700/10317\n",
      "Processing timestep 2800/10317\n",
      "Processing timestep 2900/10317\n",
      "Processing timestep 3000/10317\n",
      "Processing timestep 3100/10317\n",
      "Processing timestep 3200/10317\n",
      "Processing timestep 3300/10317\n",
      "Processing timestep 3400/10317\n",
      "Processing timestep 3500/10317\n",
      "Processing timestep 3600/10317\n",
      "Processing timestep 3700/10317\n",
      "Processing timestep 3800/10317\n",
      "Processing timestep 3900/10317\n",
      "Processing timestep 4000/10317\n",
      "Processing timestep 4100/10317\n",
      "Processing timestep 4200/10317\n",
      "Processing timestep 4300/10317\n",
      "Processing timestep 4400/10317\n",
      "Processing timestep 4500/10317\n",
      "Processing timestep 4600/10317\n",
      "Processing timestep 4700/10317\n",
      "Processing timestep 4800/10317\n",
      "Processing timestep 4900/10317\n",
      "Processing timestep 5000/10317\n",
      "Processing timestep 5100/10317\n",
      "Processing timestep 5200/10317\n",
      "Processing timestep 5300/10317\n",
      "Processing timestep 5400/10317\n",
      "Processing timestep 5500/10317\n",
      "Processing timestep 5600/10317\n",
      "Processing timestep 5700/10317\n",
      "Processing timestep 5800/10317\n",
      "Processing timestep 5900/10317\n",
      "Processing timestep 6000/10317\n",
      "Processing timestep 6100/10317\n",
      "Processing timestep 6200/10317\n",
      "Processing timestep 6300/10317\n",
      "Processing timestep 6400/10317\n",
      "Processing timestep 6500/10317\n",
      "Processing timestep 6600/10317\n",
      "Processing timestep 6700/10317\n",
      "Processing timestep 6800/10317\n",
      "Processing timestep 6900/10317\n",
      "Processing timestep 7000/10317\n",
      "Processing timestep 7100/10317\n",
      "Processing timestep 7200/10317\n",
      "Processing timestep 7300/10317\n",
      "Processing timestep 7400/10317\n",
      "Processing timestep 7500/10317\n",
      "Processing timestep 7600/10317\n",
      "Processing timestep 7700/10317\n",
      "Processing timestep 7800/10317\n",
      "Processing timestep 7900/10317\n",
      "Processing timestep 8000/10317\n",
      "Processing timestep 8100/10317\n",
      "Processing timestep 8200/10317\n",
      "Processing timestep 8300/10317\n",
      "Processing timestep 8400/10317\n",
      "Processing timestep 8500/10317\n",
      "Processing timestep 8600/10317\n",
      "Processing timestep 8700/10317\n",
      "Processing timestep 8800/10317\n",
      "Processing timestep 8900/10317\n",
      "Processing timestep 9000/10317\n",
      "Processing timestep 9100/10317\n",
      "Processing timestep 9200/10317\n",
      "Processing timestep 9300/10317\n",
      "Processing timestep 9400/10317\n",
      "Processing timestep 9500/10317\n",
      "Processing timestep 9600/10317\n",
      "Processing timestep 9700/10317\n",
      "Processing timestep 9800/10317\n",
      "Processing timestep 9900/10317\n",
      "Processing timestep 10000/10317\n",
      "Processing timestep 10100/10317\n",
      "Processing timestep 10200/10317\n",
      "Processing timestep 10300/10317\n"
     ]
    }
   ],
   "source": [
    "lev_meta = 20\n",
    "LevDo = int(DSzarr1.level[lev_meta].values)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FNS = sorted(glob.glob('/glade/derecho/scratch/wchapman/CREDIT/cesm_wxformer_00191/1981-01-02T00Z/1D/averaged_UVTQtotPSPRECTTREFHT*'))\n",
    "DSs = xr.open_mfdataset(FNS)\n",
    "nlat = DSs.sizes['latitude']\n",
    "nlon = DSs.sizes['longitude']\n",
    "ntime = DSs.sizes['time']\n",
    "\n",
    "# Initialize Diffusion and Pole Filter\n",
    "DPF = plf.Diffusion_and_Pole_Filter(nlat=nlat, nlon=nlon, device=device)\n",
    "\n",
    "# Initialize lists to store results for all times\n",
    "streamfunc_list = []\n",
    "velocity_potential_list = []\n",
    "U_rot_list = []\n",
    "V_rot_list = []\n",
    "vorticity_list = []\n",
    "divergence_list = []\n",
    "\n",
    "# Loop over all time steps\n",
    "for t in range(ntime):\n",
    "    if (t + 1) % 100 == 0:\n",
    "        print(f'Processing timestep {t + 1}/{ntime}')\n",
    "    \n",
    "    # Extract U and V at each time step\n",
    "    U = DSs['U'].isel(time=t).sel(level=lev_meta).values\n",
    "    V = DSs['V'].isel(time=t).sel(level=lev_meta).values\n",
    "    \n",
    "    # Convert to Torch tensors\n",
    "    U = torch.tensor(U).clone().detach().to(device)\n",
    "    V = torch.tensor(V).clone().detach().to(device)\n",
    "    \n",
    "    # Stack U and V\n",
    "    ugrid = torch.stack((U, V)).to(device)\n",
    "    \n",
    "    # Compute vorticity and divergence\n",
    "    vrt, div = DPF.vrtdivspec(ugrid)\n",
    "    \n",
    "    # 1. Compute Stream Function\n",
    "    streamfunc_spec = - DPF.invlap * vrt\n",
    "    streamfunc_spec *= torch.exp(-0.01 * (DPF.lap)**2)  # Smoothing\n",
    "    streamfunc = DPF.spec2grid(streamfunc_spec)\n",
    "    \n",
    "    # 2. Compute Velocity Potential\n",
    "    velocity_potential_spec = DPF.invlap * div\n",
    "    velocity_potential_spec *= torch.exp(-0.01 * (DPF.lap)**2)  # Smoothing\n",
    "    velocity_potential = DPF.spec2grid(velocity_potential_spec)\n",
    "    \n",
    "    # 3. Compute Rotational Wind Components (U_rot, V_rot)\n",
    "    U_rot, V_rot = DPF.getuv(torch.stack((streamfunc_spec, torch.zeros_like(streamfunc_spec)), dim=0))\n",
    "    \n",
    "    # Store results (detach and move to CPU for xarray compatibility)\n",
    "    streamfunc_list.append(streamfunc.cpu().detach())\n",
    "    velocity_potential_list.append(velocity_potential.cpu().detach())\n",
    "    U_rot_list.append(U_rot.cpu().detach())\n",
    "    V_rot_list.append(V_rot.cpu().detach())\n",
    "    \n",
    "    # Store vorticity and divergence\n",
    "    vorticity_list.append(DPF.spec2grid(vrt.cpu().detach()))\n",
    "    divergence_list.append(DPF.spec2grid(div.cpu().detach()))\n",
    "\n",
    "# Stack results along time dimension\n",
    "streamfunc_stack = torch.stack(streamfunc_list)\n",
    "velocity_potential_stack = torch.stack(velocity_potential_list)\n",
    "U_rot_stack = torch.stack(U_rot_list)\n",
    "V_rot_stack = torch.stack(V_rot_list)\n",
    "vorticity_stack = torch.stack(vorticity_list)\n",
    "divergence_stack = torch.stack(divergence_list)\n",
    "\n",
    "# Convert to xarray DataArrays with appropriate dimensions\n",
    "streamfunc_da = xr.DataArray(\n",
    "    streamfunc_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSs['time'], 'latitude': DSs['latitude'], 'longitude': DSs['longitude']},\n",
    "    name='stream_function'\n",
    ")\n",
    "\n",
    "velocity_potential_da = xr.DataArray(\n",
    "    velocity_potential_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSs['time'], 'latitude': DSs['latitude'], 'longitude': DSs['longitude']},\n",
    "    name='velocity_potential'\n",
    ")\n",
    "\n",
    "U_rot_da = xr.DataArray(\n",
    "    U_rot_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSs['time'], 'latitude': DSs['latitude'], 'longitude': DSs['longitude']},\n",
    "    name='U_rot'\n",
    ")\n",
    "\n",
    "V_rot_da = xr.DataArray(\n",
    "    V_rot_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSs['time'], 'latitude': DSs['latitude'], 'longitude': DSs['longitude']},\n",
    "    name='V_rot'\n",
    ")\n",
    "\n",
    "vorticity_da = xr.DataArray(\n",
    "    vorticity_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSs['time'], 'latitude': DSs['latitude'], 'longitude': DSs['longitude']},\n",
    "    name='vorticity'\n",
    ")\n",
    "\n",
    "divergence_da = xr.DataArray(\n",
    "    divergence_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSs['time'], 'latitude': DSs['latitude'], 'longitude': DSs['longitude']},\n",
    "    name='divergence'\n",
    ")\n",
    "\n",
    "# Merge into a single dataset and save\n",
    "DSmerged = xr.merge([streamfunc_da, velocity_potential_da, U_rot_da, V_rot_da, vorticity_da, divergence_da])\n",
    "DSmerged.to_netcdf(f'/glade/derecho/scratch/wchapman/CREDIT/cesm_wxformer_00191/1981-01-02T00Z/1D/SF_VP_{LevDo}mb_and_associates.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f93098-e407-419c-b36f-b4b8b942a688",
   "metadata": {},
   "source": [
    "## For CESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851ffe3-c23e-45e2-aade-b89af0769962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... taking daily mean...\n",
      "... done taking daily mean...\n",
      "Processing timestep 10/13140\n",
      "Processing timestep 20/13140\n",
      "Processing timestep 30/13140\n",
      "Processing timestep 40/13140\n",
      "Processing timestep 50/13140\n",
      "Processing timestep 60/13140\n",
      "Processing timestep 70/13140\n",
      "Processing timestep 80/13140\n",
      "Processing timestep 90/13140\n",
      "Processing timestep 100/13140\n",
      "Processing timestep 110/13140\n",
      "Processing timestep 120/13140\n",
      "Processing timestep 130/13140\n",
      "Processing timestep 140/13140\n",
      "Processing timestep 150/13140\n",
      "Processing timestep 160/13140\n",
      "Processing timestep 170/13140\n",
      "Processing timestep 180/13140\n",
      "Processing timestep 190/13140\n",
      "Processing timestep 200/13140\n",
      "Processing timestep 210/13140\n",
      "Processing timestep 220/13140\n",
      "Processing timestep 230/13140\n",
      "Processing timestep 240/13140\n",
      "Processing timestep 250/13140\n",
      "Processing timestep 260/13140\n",
      "Processing timestep 270/13140\n",
      "Processing timestep 280/13140\n",
      "Processing timestep 290/13140\n",
      "Processing timestep 300/13140\n",
      "Processing timestep 310/13140\n",
      "Processing timestep 320/13140\n",
      "Processing timestep 330/13140\n",
      "Processing timestep 340/13140\n",
      "Processing timestep 350/13140\n",
      "Processing timestep 360/13140\n",
      "Processing timestep 370/13140\n",
      "Processing timestep 380/13140\n",
      "Processing timestep 390/13140\n",
      "Processing timestep 400/13140\n",
      "Processing timestep 410/13140\n",
      "Processing timestep 420/13140\n",
      "Processing timestep 430/13140\n",
      "Processing timestep 440/13140\n",
      "Processing timestep 450/13140\n",
      "Processing timestep 460/13140\n",
      "Processing timestep 470/13140\n",
      "Processing timestep 480/13140\n",
      "Processing timestep 490/13140\n",
      "Processing timestep 500/13140\n",
      "Processing timestep 510/13140\n",
      "Processing timestep 520/13140\n",
      "Processing timestep 530/13140\n",
      "Processing timestep 540/13140\n",
      "Processing timestep 550/13140\n",
      "Processing timestep 560/13140\n",
      "Processing timestep 570/13140\n",
      "Processing timestep 580/13140\n",
      "Processing timestep 590/13140\n",
      "Processing timestep 600/13140\n",
      "Processing timestep 610/13140\n",
      "Processing timestep 620/13140\n",
      "Processing timestep 630/13140\n",
      "Processing timestep 640/13140\n",
      "Processing timestep 650/13140\n",
      "Processing timestep 660/13140\n",
      "Processing timestep 670/13140\n",
      "Processing timestep 680/13140\n",
      "Processing timestep 690/13140\n",
      "Processing timestep 700/13140\n",
      "Processing timestep 710/13140\n",
      "Processing timestep 720/13140\n",
      "Processing timestep 730/13140\n",
      "Processing timestep 740/13140\n",
      "Processing timestep 750/13140\n",
      "Processing timestep 760/13140\n",
      "Processing timestep 770/13140\n",
      "Processing timestep 780/13140\n",
      "Processing timestep 790/13140\n",
      "Processing timestep 800/13140\n",
      "Processing timestep 810/13140\n",
      "Processing timestep 820/13140\n",
      "Processing timestep 830/13140\n",
      "Processing timestep 840/13140\n",
      "Processing timestep 850/13140\n",
      "Processing timestep 860/13140\n",
      "Processing timestep 870/13140\n",
      "Processing timestep 880/13140\n",
      "Processing timestep 890/13140\n",
      "Processing timestep 900/13140\n",
      "Processing timestep 910/13140\n",
      "Processing timestep 920/13140\n",
      "Processing timestep 930/13140\n",
      "Processing timestep 940/13140\n",
      "Processing timestep 950/13140\n",
      "Processing timestep 960/13140\n",
      "Processing timestep 970/13140\n",
      "Processing timestep 980/13140\n",
      "Processing timestep 990/13140\n",
      "Processing timestep 1000/13140\n",
      "Processing timestep 1010/13140\n",
      "Processing timestep 1020/13140\n",
      "Processing timestep 1030/13140\n",
      "Processing timestep 1040/13140\n",
      "Processing timestep 1050/13140\n",
      "Processing timestep 1060/13140\n",
      "Processing timestep 1070/13140\n",
      "Processing timestep 1080/13140\n",
      "Processing timestep 1090/13140\n",
      "Processing timestep 1100/13140\n",
      "Processing timestep 1110/13140\n",
      "Processing timestep 1120/13140\n",
      "Processing timestep 1130/13140\n",
      "Processing timestep 1140/13140\n",
      "Processing timestep 1150/13140\n",
      "Processing timestep 1160/13140\n",
      "Processing timestep 1170/13140\n",
      "Processing timestep 1180/13140\n",
      "Processing timestep 1190/13140\n",
      "Processing timestep 1200/13140\n",
      "Processing timestep 1210/13140\n",
      "Processing timestep 1220/13140\n",
      "Processing timestep 1230/13140\n",
      "Processing timestep 1240/13140\n",
      "Processing timestep 1250/13140\n",
      "Processing timestep 1260/13140\n",
      "Processing timestep 1270/13140\n",
      "Processing timestep 1280/13140\n",
      "Processing timestep 1290/13140\n",
      "Processing timestep 1300/13140\n",
      "Processing timestep 1310/13140\n",
      "Processing timestep 1320/13140\n",
      "Processing timestep 1330/13140\n",
      "Processing timestep 1340/13140\n",
      "Processing timestep 1350/13140\n",
      "Processing timestep 1360/13140\n",
      "Processing timestep 1370/13140\n",
      "Processing timestep 1380/13140\n",
      "Processing timestep 1390/13140\n",
      "Processing timestep 1400/13140\n",
      "Processing timestep 1410/13140\n",
      "Processing timestep 1420/13140\n",
      "Processing timestep 1430/13140\n",
      "Processing timestep 1440/13140\n",
      "Processing timestep 1450/13140\n",
      "Processing timestep 1460/13140\n",
      "Processing timestep 1470/13140\n",
      "Processing timestep 1480/13140\n",
      "Processing timestep 1490/13140\n",
      "Processing timestep 1500/13140\n",
      "Processing timestep 1510/13140\n",
      "Processing timestep 1520/13140\n",
      "Processing timestep 1530/13140\n",
      "Processing timestep 1540/13140\n",
      "Processing timestep 1550/13140\n",
      "Processing timestep 1560/13140\n",
      "Processing timestep 1570/13140\n",
      "Processing timestep 1580/13140\n",
      "Processing timestep 1590/13140\n",
      "Processing timestep 1600/13140\n",
      "Processing timestep 1610/13140\n",
      "Processing timestep 1620/13140\n",
      "Processing timestep 1630/13140\n",
      "Processing timestep 1640/13140\n",
      "Processing timestep 1650/13140\n",
      "Processing timestep 1660/13140\n",
      "Processing timestep 1670/13140\n",
      "Processing timestep 1680/13140\n",
      "Processing timestep 1690/13140\n",
      "Processing timestep 1700/13140\n",
      "Processing timestep 1710/13140\n",
      "Processing timestep 1720/13140\n",
      "Processing timestep 1730/13140\n",
      "Processing timestep 1740/13140\n",
      "Processing timestep 1750/13140\n",
      "Processing timestep 1760/13140\n",
      "Processing timestep 1770/13140\n",
      "Processing timestep 1780/13140\n",
      "Processing timestep 1790/13140\n",
      "Processing timestep 1800/13140\n",
      "Processing timestep 1810/13140\n",
      "Processing timestep 1820/13140\n",
      "Processing timestep 1830/13140\n",
      "Processing timestep 1840/13140\n",
      "Processing timestep 1850/13140\n",
      "Processing timestep 1860/13140\n",
      "Processing timestep 1870/13140\n",
      "Processing timestep 1880/13140\n",
      "Processing timestep 1890/13140\n",
      "Processing timestep 1900/13140\n",
      "Processing timestep 1910/13140\n",
      "Processing timestep 1920/13140\n",
      "Processing timestep 1930/13140\n",
      "Processing timestep 1940/13140\n",
      "Processing timestep 1950/13140\n",
      "Processing timestep 1960/13140\n",
      "Processing timestep 1970/13140\n",
      "Processing timestep 1980/13140\n",
      "Processing timestep 1990/13140\n",
      "Processing timestep 2000/13140\n",
      "Processing timestep 2010/13140\n",
      "Processing timestep 2020/13140\n",
      "Processing timestep 2030/13140\n",
      "Processing timestep 2040/13140\n",
      "Processing timestep 2050/13140\n",
      "Processing timestep 2060/13140\n",
      "Processing timestep 2070/13140\n",
      "Processing timestep 2080/13140\n",
      "Processing timestep 2090/13140\n",
      "Processing timestep 2100/13140\n",
      "Processing timestep 2110/13140\n",
      "Processing timestep 2120/13140\n",
      "Processing timestep 2130/13140\n",
      "Processing timestep 2140/13140\n",
      "Processing timestep 2150/13140\n",
      "Processing timestep 2160/13140\n",
      "Processing timestep 2170/13140\n",
      "Processing timestep 2180/13140\n",
      "Processing timestep 2190/13140\n",
      "Processing timestep 2200/13140\n",
      "Processing timestep 2210/13140\n",
      "Processing timestep 2220/13140\n",
      "Processing timestep 2230/13140\n",
      "Processing timestep 2240/13140\n",
      "Processing timestep 2250/13140\n",
      "Processing timestep 2260/13140\n",
      "Processing timestep 2270/13140\n",
      "Processing timestep 2280/13140\n",
      "Processing timestep 2290/13140\n",
      "Processing timestep 2300/13140\n",
      "Processing timestep 2310/13140\n",
      "Processing timestep 2320/13140\n",
      "Processing timestep 2330/13140\n",
      "Processing timestep 2340/13140\n",
      "Processing timestep 2350/13140\n",
      "Processing timestep 2360/13140\n",
      "Processing timestep 2370/13140\n",
      "Processing timestep 2380/13140\n",
      "Processing timestep 2390/13140\n",
      "Processing timestep 2400/13140\n",
      "Processing timestep 2410/13140\n",
      "Processing timestep 2420/13140\n",
      "Processing timestep 2430/13140\n",
      "Processing timestep 2440/13140\n",
      "Processing timestep 2450/13140\n",
      "Processing timestep 2460/13140\n",
      "Processing timestep 2470/13140\n",
      "Processing timestep 2480/13140\n",
      "Processing timestep 2490/13140\n",
      "Processing timestep 2500/13140\n",
      "Processing timestep 2510/13140\n",
      "Processing timestep 2520/13140\n",
      "Processing timestep 2530/13140\n",
      "Processing timestep 2540/13140\n",
      "Processing timestep 2550/13140\n",
      "Processing timestep 2560/13140\n",
      "Processing timestep 2570/13140\n",
      "Processing timestep 2580/13140\n",
      "Processing timestep 2590/13140\n",
      "Processing timestep 2600/13140\n",
      "Processing timestep 2610/13140\n",
      "Processing timestep 2620/13140\n",
      "Processing timestep 2630/13140\n",
      "Processing timestep 2640/13140\n",
      "Processing timestep 2650/13140\n",
      "Processing timestep 2660/13140\n",
      "Processing timestep 2670/13140\n",
      "Processing timestep 2680/13140\n",
      "Processing timestep 2690/13140\n",
      "Processing timestep 2700/13140\n",
      "Processing timestep 2710/13140\n",
      "Processing timestep 2720/13140\n",
      "Processing timestep 2730/13140\n",
      "Processing timestep 2740/13140\n",
      "Processing timestep 2750/13140\n",
      "Processing timestep 2760/13140\n",
      "Processing timestep 2770/13140\n",
      "Processing timestep 2780/13140\n",
      "Processing timestep 2790/13140\n",
      "Processing timestep 2800/13140\n",
      "Processing timestep 2810/13140\n",
      "Processing timestep 2820/13140\n",
      "Processing timestep 2830/13140\n",
      "Processing timestep 2840/13140\n",
      "Processing timestep 2850/13140\n",
      "Processing timestep 2860/13140\n",
      "Processing timestep 2870/13140\n",
      "Processing timestep 2880/13140\n",
      "Processing timestep 2890/13140\n",
      "Processing timestep 2900/13140\n",
      "Processing timestep 2910/13140\n",
      "Processing timestep 2920/13140\n",
      "Processing timestep 2930/13140\n",
      "Processing timestep 2940/13140\n",
      "Processing timestep 2950/13140\n",
      "Processing timestep 2960/13140\n",
      "Processing timestep 2970/13140\n",
      "Processing timestep 2980/13140\n",
      "Processing timestep 2990/13140\n",
      "Processing timestep 3000/13140\n",
      "Processing timestep 3010/13140\n",
      "Processing timestep 3020/13140\n",
      "Processing timestep 3030/13140\n",
      "Processing timestep 3040/13140\n",
      "Processing timestep 3050/13140\n",
      "Processing timestep 3060/13140\n",
      "Processing timestep 3070/13140\n",
      "Processing timestep 3080/13140\n",
      "Processing timestep 3090/13140\n",
      "Processing timestep 3100/13140\n",
      "Processing timestep 3110/13140\n",
      "Processing timestep 3120/13140\n",
      "Processing timestep 3130/13140\n",
      "Processing timestep 3140/13140\n"
     ]
    }
   ],
   "source": [
    "lev_meta = 20\n",
    "LevDo = int(DSzarr1.level[lev_meta].values)\n",
    "\n",
    "print('... taking daily mean...')\n",
    "DSzarr1 = DSzarr1[['U','V']].sel(level=LevDo, method='nearest').resample(time='1D').mean()\n",
    "print('...loading...')\n",
    "DSzarr1 = DSzarr1.load()\n",
    "print('... done taking daily mean...')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nlat = DSzarr1.sizes['latitude']\n",
    "nlon = DSzarr1.sizes['longitude']\n",
    "ntime = DSzarr1.sizes['time']\n",
    "\n",
    "# Initialize Diffusion and Pole Filter\n",
    "DPF = plf.Diffusion_and_Pole_Filter(nlat=nlat, nlon=nlon, device=device)\n",
    "\n",
    "# Initialize lists to store results for all times\n",
    "streamfunc_list = []\n",
    "velocity_potential_list = []\n",
    "U_rot_list = []\n",
    "V_rot_list = []\n",
    "vorticity_list = []\n",
    "divergence_list = []\n",
    "\n",
    "# Loop over all time steps\n",
    "for t in range(ntime):\n",
    "    if (t + 1) % 100 == 0:\n",
    "        print(f'Processing timestep {t + 1}/{ntime}')\n",
    "    \n",
    "    # Extract U and V at each time step\n",
    "    U = DSzarr1['U'].isel(time=t).values\n",
    "    V = DSzarr1['V'].isel(time=t).values\n",
    "    \n",
    "    # Convert to Torch tensors\n",
    "    U = torch.tensor(U).clone().detach().to(device)\n",
    "    V = torch.tensor(V).clone().detach().to(device)\n",
    "    \n",
    "    # Stack U and V\n",
    "    ugrid = torch.stack((U, V)).to(device)\n",
    "    \n",
    "    # Compute vorticity and divergence\n",
    "    vrt, div = DPF.vrtdivspec(ugrid)\n",
    "    \n",
    "    # 1. Compute Stream Function\n",
    "    streamfunc_spec = - DPF.invlap * vrt\n",
    "    streamfunc_spec *= torch.exp(-0.01 * (DPF.lap)**2)  # Smoothing\n",
    "    streamfunc = DPF.spec2grid(streamfunc_spec)\n",
    "    \n",
    "    # 2. Compute Velocity Potential\n",
    "    velocity_potential_spec = DPF.invlap * div\n",
    "    velocity_potential_spec *= torch.exp(-0.01 * (DPF.lap)**2)  # Smoothing\n",
    "    velocity_potential = DPF.spec2grid(velocity_potential_spec)\n",
    "    \n",
    "    # 3. Compute Rotational Wind Components (U_rot, V_rot)\n",
    "    U_rot, V_rot = DPF.getuv(torch.stack((streamfunc_spec, torch.zeros_like(streamfunc_spec)), dim=0))\n",
    "    \n",
    "    # Store results (detach and move to CPU for xarray compatibility)\n",
    "    streamfunc_list.append(streamfunc.cpu().detach())\n",
    "    velocity_potential_list.append(velocity_potential.cpu().detach())\n",
    "    U_rot_list.append(U_rot.cpu().detach())\n",
    "    V_rot_list.append(V_rot.cpu().detach())\n",
    "    \n",
    "    # Store vorticity and divergence\n",
    "    vorticity_list.append(DPF.spec2grid(vrt.cpu().detach()))\n",
    "    divergence_list.append(DPF.spec2grid(div.cpu().detach()))\n",
    "\n",
    "# Stack results along time dimension\n",
    "streamfunc_stack = torch.stack(streamfunc_list)\n",
    "velocity_potential_stack = torch.stack(velocity_potential_list)\n",
    "U_rot_stack = torch.stack(U_rot_list)\n",
    "V_rot_stack = torch.stack(V_rot_list)\n",
    "vorticity_stack = torch.stack(vorticity_list)\n",
    "divergence_stack = torch.stack(divergence_list)\n",
    "\n",
    "# Convert to xarray DataArrays with appropriate dimensions\n",
    "streamfunc_da = xr.DataArray(\n",
    "    streamfunc_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSzarr1['time'], 'latitude': DSzarr1['latitude'], 'longitude': DSzarr1['longitude']},\n",
    "    name='stream_function'\n",
    ")\n",
    "\n",
    "velocity_potential_da = xr.DataArray(\n",
    "    velocity_potential_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSzarr1['time'], 'latitude': DSzarr1['latitude'], 'longitude': DSzarr1['longitude']},\n",
    "    name='velocity_potential'\n",
    ")\n",
    "\n",
    "U_rot_da = xr.DataArray(\n",
    "    U_rot_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSzarr1['time'], 'latitude': DSzarr1['latitude'], 'longitude': DSzarr1['longitude']},\n",
    "    name='U_rot'\n",
    ")\n",
    "\n",
    "V_rot_da = xr.DataArray(\n",
    "    V_rot_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSzarr1['time'], 'latitude': DSzarr1['latitude'], 'longitude': DSzarr1['longitude']},\n",
    "    name='V_rot'\n",
    ")\n",
    "\n",
    "vorticity_da = xr.DataArray(\n",
    "    vorticity_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSzarr1['time'], 'latitude': DSzarr1['latitude'], 'longitude': DSzarr1['longitude']},\n",
    "    name='vorticity'\n",
    ")\n",
    "\n",
    "divergence_da = xr.DataArray(\n",
    "    divergence_stack.numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={'time': DSzarr1['time'], 'latitude': DSzarr1['latitude'], 'longitude': DSzarr1['longitude']},\n",
    "    name='divergence'\n",
    ")\n",
    "\n",
    "# Merge into a single dataset and save\n",
    "DSmerged = xr.merge([streamfunc_da, velocity_potential_da, U_rot_da, V_rot_da, vorticity_da, divergence_da])\n",
    "DSmerged.to_netcdf(f'/glade/derecho/scratch/wchapman/CREDIT/cesm_wxformer_00191/1981-01-02T00Z/1D/SF_VP_CESM_{LevDo}mb_and_associates.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07492ec7-229d-47a4-8f1e-e777b1ee1d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (credit)",
   "language": "python",
   "name": "credit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
